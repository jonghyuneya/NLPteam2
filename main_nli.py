# main_nli.py (NLI ê¸°ë°˜ ë ˆìŠ¤í† ë‘ ì¸¡ë©´ ë¶„ì„)
import argparse
from pathlib import Path
import pandas as pd
import re
import time

from config import (
    PATH_BUSINESS, PATH_REVIEW,
    PATH_REVIEWS_FILTERED, PATH_SENT_WITH_SENT, PATH_WITH_TOPICS,
    SENTIMENT_MODEL, EMBEDDING_MODEL
)
from modules.find_business_ids import find_business_ids
from modules.filter_reviews import filter_reviews_by_business_ids
from modules.sentence_sentiment import run_sentence_sentiment
from modules.business_meta import load_business_meta
from modules.nli_multilabel_final import apply_nli_aspect_analysis  # ìƒˆë¡œìš´ ëª¨ë“ˆ


def parse_args():
    p = argparse.ArgumentParser(
        description="Restaurant Aspect Analysis Pipeline: NLI-based multi-label classification for 33 restaurant aspects (10+ word sentences)"
    )
    # ëŒ€ìƒ ë¹„ì¦ˆë‹ˆìŠ¤ ì„ íƒ
    p.add_argument("--name-substr", type=str, default=None)
    p.add_argument("--category", type=str, default="Restaurants")
    p.add_argument("--city", type=str, default=None)
    p.add_argument("--state", type=str, default=None)
    p.add_argument("--biz-id", action="append", help="Explicit business_id (can repeat)")
    p.add_argument("--limit", type=int, default=2)

    # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì„ íƒ
    p.add_argument("--skip-filter", action="store_true", help="Skip review filtering (use existing filtered file)")
    p.add_argument("--skip-sentiment", action="store_true", help="Skip sentiment analysis (use existing sentiment file)")
    p.add_argument("--do-aspect-analysis", action="store_true", help="Run NLI aspect analysis")
    p.add_argument("--aspect-only", action="store_true", help="Only run aspect analysis (skip all preprocessing)")
    
    # ğŸš€ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ìµœì í™” ì˜µì…˜
    p.add_argument("--quick-test", action="store_true", help="Quick test mode: sample 100 sentences per business")
    p.add_argument("--sample-size", type=int, default=100, help="Number of sentences to sample per business in quick test")
    p.add_argument("--test-single-biz", action="store_true", help="Test with only the first business found")
    
    # ë¶„ì„ ìŠ¤ì½”í”„
    p.add_argument("--analysis-scope", type=str, default="per-store",
                   choices=["per-store", "pooled", "both"],
                   help="Run analysis per store, pooled across stores, or both")

    # ì„ê³„ì¹˜(ì—…ì²´ë³„ ìµœì†Œ ë¬¸ì¥/ë¦¬ë·° ìˆ˜)
    p.add_argument("--per-store-min-sentences", type=int, default=20,
                   help="Run per-store analysis only if sentence count â‰¥ this (default: 20)")
    p.add_argument("--per-store-min-reviews", type=int, default=0,
                   help="Optional: pre-filter stores by raw review count (0=ignore)")

    # ğŸ¯ NLI íŒŒë¼ë¯¸í„°
    p.add_argument("--nli-model", type=str, default="MoritzLaurer/DeBERTa-v3-base-mnli",
                   choices=[
                       "MoritzLaurer/DeBERTa-v3-base-mnli",        
                       "microsoft/deberta-v3-large-mnli",      
                       "microsoft/deberta-base-mnli",           # í´ë˜ì‹ ë²„ì „
                       "microsoft/deberta-large-mnli",          # í´ë˜ì‹ ëŒ€í˜•
                       "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli",  # ë©€í‹° ë°ì´í„°ì…‹ í›ˆë ¨
                       "facebook/bart-large-mnli",              # BART (ë¹„êµìš©)
                       "roberta-large-mnli"                     # RoBERTa (ë¹„êµìš©)
                   ],
                   help="NLI model for classification (DeBERTa recommended for best performance)")
    p.add_argument("--min-prob", type=float, default=0.8,  # DeBERTa ìµœì ê°’
                   help="Minimum probability threshold (0.35 recommended for DeBERTa)")
    p.add_argument("--batch-size", type=int, default=8,  # ë¡œì»¬ ìµœì í™”
                   help="Batch size for NLI processing")
    p.add_argument("--local-only", action="store_true", default=True,
                   help="Use only cached models (no online download)")

    # ì¶œë ¥ ê²½ë¡œ/íŒŒì¼ëª…
    p.add_argument("--out-dir", type=str, default="./outputs_aspect_analysis",
                   help="Directory for aspect analysis outputs")
    p.add_argument("--filename-template", type=str,
                   default="aspect_analysis__{scope}__{addr_slug}.csv",
                   help="Placeholders: {scope}, {addr_slug}")

    # ì‹¤í–‰ ìš”ì•½ ì¸ë±ìŠ¤ íŒŒì¼  
    p.add_argument("--write-index", action="store_true", default=True,
                   help="Write an index CSV summarizing per-store run status")
    
    # ğŸ” ë””ë²„ê¹… ì˜µì…˜
    p.add_argument("--verbose", action="store_true", help="Verbose output for debugging")
    p.add_argument("--dry-run", action="store_true", help="Dry run: show what would be done without executing")

    return p.parse_args()


def slugify(s: str, max_len: int = 60) -> str:
    s = (s or "").lower()
    s = re.sub(r"[^a-z0-9]+", "-", s).strip("-")
    if len(s) > max_len:
        s = s[:max_len].rstrip("-")
    return s or "store"


def sample_sentences_for_quick_test(sent_df: pd.DataFrame, sample_size: int, verbose: bool = False) -> pd.DataFrame:
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë¬¸ì¥ ìƒ˜í”Œë§"""
    if len(sent_df) <= sample_size:
        if verbose:
            print(f"[Quick Test] Dataset size ({len(sent_df)}) â‰¤ sample size ({sample_size}), using all data")
        return sent_df
    
    # ê° ë¹„ì¦ˆë‹ˆìŠ¤ì—ì„œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
    sampled_dfs = []
    for biz_id in sent_df['business_id'].unique():
        biz_data = sent_df[sent_df['business_id'] == biz_id]
        biz_sample_size = min(sample_size // len(sent_df['business_id'].unique()), len(biz_data))
        biz_sample = biz_data.sample(n=biz_sample_size, random_state=42)
        sampled_dfs.append(biz_sample)
        if verbose:
            print(f"[Quick Test] Business {biz_id}: sampled {len(biz_sample)}/{len(biz_data)} sentences")
    
    result = pd.concat(sampled_dfs, ignore_index=True)
    if verbose:
        print(f"[Quick Test] Total sampled: {len(result)}/{len(sent_df)} sentences")
    return result


def main():
    args = parse_args()
    start_time = time.time()
    
    if args.verbose:
        print("ğŸ½ï¸ Starting Restaurant Aspect Analysis Pipeline")
        print(f"âš™ï¸ Config: min_prob={args.min_prob}, batch_size={args.batch_size}, model={args.nli_model}")
        print("ğŸ¯ Analyzing 33 core restaurant aspects (service, food, ambience, etc.)")
        print("ğŸ“ Processing sentences with 10+ words only")
        if args.quick_test:
            print(f"âš¡ Quick test mode: {args.sample_size} sentences per business")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    if args.dry_run:
        print(f"[DRY RUN] Would create output directory: {out_dir}")
    
    # ğŸ¯ Aspect-only ëª¨ë“œ: ê¸°ì¡´ sentiment íŒŒì¼ë§Œ ì‚¬ìš©
    if args.aspect_only:
        if not Path(PATH_SENT_WITH_SENT).exists():
            raise SystemExit(f"âŒ Aspect-only mode requires existing sentiment file: {PATH_SENT_WITH_SENT}")
        
        print(f"[Aspect-Only Mode] Using existing sentiment file: {PATH_SENT_WITH_SENT}")
        sent_df = pd.read_csv(PATH_SENT_WITH_SENT)
        
        if args.quick_test:
            sent_df = sample_sentences_for_quick_test(sent_df, args.sample_size, args.verbose)
        
        if args.test_single_biz:
            first_biz = sent_df['business_id'].iloc[0]
            sent_df = sent_df[sent_df['business_id'] == first_biz]
            print(f"[Test Single Biz] Using only business: {first_biz}")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        biz_ids = sent_df['business_id'].unique().tolist()
        id2meta = load_business_meta(str(PATH_BUSINESS), biz_ids)
        
        # ë°”ë¡œ ì¸¡ë©´ ë¶„ì„ìœ¼ë¡œ ì í”„
        jump_to_aspect_analysis(args, sent_df, id2meta, out_dir)
        return

    # 1) ëŒ€ìƒ business_id ê²°ì •
    if args.biz_id:
        biz_ids = args.biz_id
    else:
        biz_ids = find_business_ids(
            business_json_path=str(PATH_BUSINESS),
            name_substring=args.name_substr,
            category_keyword=args.category,
            city=args.city,
            state=args.state,
            limit=args.limit
        )
    
    if not biz_ids:
        raise SystemExit("âŒ No business matched. Try different filters or supply --biz-id.")
    
    if args.test_single_biz:
        biz_ids = biz_ids[:1]
        print(f"[Test Single Biz] Using only: {biz_ids[0]}")
    
    print(f"[Picked business_id(s)] {biz_ids}")

    # 1.5) business.jsonlì—ì„œ ì£¼ì†Œ/ì´ë¦„ ë©”íƒ€ ë¡œë“œ
    id2meta = load_business_meta(str(PATH_BUSINESS), biz_ids)
    
    if args.verbose:
        for bid in biz_ids:
            meta = id2meta.get(bid, {}) or {}
            print(f"  â€¢ {bid}: {meta.get('name', 'Unknown')} - {meta.get('address', 'Unknown')}")

    # 2) ë¦¬ë·° í•„í„° â†’ í†µí•© JSONL
    if not args.skip_filter and not args.dry_run:
        print("[Step 1/3] Filtering reviews...")
        kept = filter_reviews_by_business_ids(
            review_json_path=str(PATH_REVIEW),
            target_business_ids=biz_ids,
            out_jsonl_path=str(PATH_REVIEWS_FILTERED),
        )
        print(f"âœ… Filtered reviews: kept={kept} â†’ {PATH_REVIEWS_FILTERED}")
    elif args.dry_run:
        print(f"[DRY RUN] Would filter reviews for {len(biz_ids)} businesses")
    else:
        print("[Skip] Review filtering")

    # 3) ë¬¸ì¥ ë‹¨ìœ„ ê°ì„±
    if not args.skip_sentiment and not args.dry_run:
        print("[Step 2/3] Sentence sentiment analysis...")
        run_sentence_sentiment(
            filtered_jsonl_path=str(PATH_REVIEWS_FILTERED),
            out_csv_path=str(PATH_SENT_WITH_SENT),
            sentiment_model=SENTIMENT_MODEL,
            max_chars=256,
            batch_size=64
        )
        print(f"âœ… Sentence sentiment â†’ {PATH_SENT_WITH_SENT}")
    elif args.dry_run:
        print(f"[DRY RUN] Would run sentiment analysis")
    else:
        print("[Skip] Sentiment analysis")

    # 4) ì¸¡ë©´ ë¶„ì„
    if args.do_aspect_analysis and not args.dry_run:
        sent_df = pd.read_csv(PATH_SENT_WITH_SENT)
        
        if args.quick_test:
            sent_df = sample_sentences_for_quick_test(sent_df, args.sample_size, args.verbose)
        
        jump_to_aspect_analysis(args, sent_df, id2meta, out_dir)
    elif args.dry_run:
        print(f"[DRY RUN] Would run aspect analysis with {args.analysis_scope} scope")
    else:
        print("[Skip] Aspect analysis (use --do-aspect-analysis to enable)")
    
    elapsed = time.time() - start_time
    print(f"ğŸ‰ Restaurant Aspect Analysis Pipeline completed in {elapsed:.1f} seconds")
    

def jump_to_aspect_analysis(args, sent_df: pd.DataFrame, id2meta: dict, out_dir: Path):
    """ì¸¡ë©´ ë¶„ì„ ì‹¤í–‰"""
    print("[Step 3/3] Restaurant Aspect Analysis (33 aspects, 10+ word sentences)...")
    
    # 3.5) ì—…ì²´ë³„ ë¬¸ì¥/ë¦¬ë·° ìˆ˜ ì§‘ê³„
    sent_counts = sent_df.groupby("business_id").size().to_dict()
    
    review_counts = None
    if args.per_store_min_reviews > 0:
        if "review_id" in sent_df.columns:
            review_counts = (
                sent_df.drop_duplicates(["business_id", "review_id"])
                      .groupby("business_id").size().to_dict()
            )
        else:
            print("[Warn] per-store-min-reviews requested but review_id not found; skipping this filter.")

    # ì£¼ì†Œ â†’ ìŠ¬ëŸ¬ê·¸ ë§¤í•‘(+ì¶©ëŒ íšŒí”¼)
    seen_addr = {}
    def addr_slug_of(bid: str) -> str:
        meta = id2meta.get(bid, {}) or {}
        base = meta.get("address") or meta.get("name") or "store"
        s = slugify(base, max_len=60)
        cnt = seen_addr.get(s, 0) + 1
        seen_addr[s] = cnt
        return s if cnt == 1 else f"{s}-{cnt}"

    # ê³µí†µ ëŸ¬ë„ˆ
    def run_aspect_analysis(scope: str, business_id, out_base_path: Path):
        if args.verbose:
            print(f"ğŸ” Running aspect analysis: scope={scope}, business_id={business_id}")
            
        start_time = time.time()
        
        result_df, summary_df = apply_nli_aspect_analysis(
            sentences_csv_path=str(PATH_SENT_WITH_SENT),
            out_csv_path=str(out_base_path),
            business_id=business_id,
            nli_model=args.nli_model,
            min_prob=args.min_prob,
            batch_size=args.batch_size,
            local_files_only=args.local_only,
            business_meta=id2meta
        )
        
        elapsed = time.time() - start_time
        base = str(out_base_path)
        
        print(f"âœ… Aspect analysis complete: scope={scope}, business_id={business_id} ({elapsed:.1f}s)")
        print(f"   ğŸ“Š Results: {len(summary_df)} aspects found, {len(result_df)} sentences analyzed")
        print("   ğŸ“ Output files:")
        print(f"      â€¢ Sentence-level results: {base}")
        print(f"      â€¢ Aspect summary       : {base.replace('.csv', '_aspect_summary.csv')}")
        print(f"      â€¢ Monthly trends       : {base.replace('.csv', '_aspect_trends.csv')}")
        print(f"      â€¢ Example sentences    : {base.replace('.csv', '_aspect_examples.csv')}")
        
        if args.verbose:
            # ê°„ë‹¨í•œ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            total_aspects = len(summary_df)
            if total_aspects > 0:
                top_aspect = summary_df.iloc[0]
                print(f"   ğŸ“ˆ Analysis preview: {total_aspects} aspects with mentions")
                print(f"   ğŸ† Top aspect: {top_aspect['aspect']} ({top_aspect['n_sentences']} mentions)")
                print(f"   ğŸ“ Avg sentences per aspect: {summary_df['n_sentences'].mean():.1f}")
        
        return base, summary_df

    run_index = []
    biz_ids = sent_df['business_id'].unique().tolist()

    # (a) í†µí•©(POOLED) ë¶„ì„
    if args.analysis_scope in ("pooled", "both"):
        print(f"ğŸŒ Running pooled analysis across {len(biz_ids)} businesses...")
        pooled_name = args.filename_template.format(scope="pooled", addr_slug="all-stores")
        pooled_path = out_dir / pooled_name
        
        base, summary_df = run_aspect_analysis("pooled", None, pooled_path)
        
        run_index.append({
            "scope": "pooled",
            "business_id": "ALL",
            "business_address": "ALL",
            "n_sentences": int(len(sent_df)),
            "n_reviews": int(sent_df["review_id"].nunique()) if "review_id" in sent_df.columns else None,
            "n_aspects_found": len(summary_df),
            "status": "analyzed",
            "output_base": base
        })

    # (b) ì—…ì²´ë³„ ë¶„ì„ (ì„ê³„ì¹˜ í•„í„° ì ìš©)
    if args.analysis_scope in ("per-store", "both"):
        MIN_S = int(args.per_store_min_sentences)
        MIN_R = int(args.per_store_min_reviews)
        
        print(f"ğŸª Running per-store analysis (min {MIN_S} sentences, {MIN_R} reviews)...")

        for bid in biz_ids:
            n_s = int(sent_counts.get(bid, 0))
            n_r = int(review_counts.get(bid, 0)) if (review_counts is not None) else None

            if n_s < MIN_S:
                print(f"â­ Skip {bid}: sentences={n_s} < {MIN_S}")
                run_index.append({
                    "scope":"per-store","business_id":bid,
                    "business_address": (id2meta.get(bid, {}) or {}).get("address",""),
                    "n_sentences":n_s,"n_reviews":n_r,"n_aspects_found":0,
                    "status":"skipped_low_sentences","output_base":None
                })
                continue
                
            if (review_counts is not None) and (n_r < MIN_R):
                print(f"â­ Skip {bid}: reviews={n_r} < {MIN_R}")
                run_index.append({
                    "scope":"per-store","business_id":bid,
                    "business_address": (id2meta.get(bid, {}) or {}).get("address",""),
                    "n_sentences":n_s,"n_reviews":n_r,"n_aspects_found":0,
                    "status":"skipped_low_reviews","output_base":None
                })
                continue

            addr_slug = addr_slug_of(bid)
            fname = args.filename_template.format(scope="perstore", addr_slug=addr_slug)
            out_path = out_dir / fname
            
            base, summary_df = run_aspect_analysis("per-store", bid, out_path)
            
            run_index.append({
                "scope":"per-store","business_id":bid,
                "business_address": (id2meta.get(bid, {}) or {}).get("address",""),
                "n_sentences":n_s,"n_reviews":n_r,
                "n_aspects_found": len(summary_df),
                "status":"analyzed","output_base":base
            })

    # 5) ì‹¤í–‰ ì¸ë±ìŠ¤ ì €ì¥
    if args.write_index and run_index:
        idx_path = out_dir / "aspect_analysis_index.csv"
        index_df = pd.DataFrame(run_index)
        index_df.to_csv(idx_path, index=False, encoding="utf-8")
        print(f"ğŸ“‹ Analysis index saved â†’ {idx_path}")
        
        if args.verbose:
            print("ğŸ“Š Analysis Summary:")
            print(index_df.groupby(['scope', 'status']).size().to_string())


if __name__ == "__main__":
    main()